	\documentclass[fleqn, 12pt]{article}
	\usepackage[latin1]{inputenc}
	\usepackage[ngerman]{babel}
	\usepackage[a4paper,text={155mm,220mm},centering,headsep=10mm,footskip=15mm]{geometry}
	\usepackage{graphicx}
	\usepackage{amssymb}
	\usepackage{graphicx}
	\usepackage{multirow}
	\usepackage{multicol}
	\usepackage{pst-plot}
	\usepackage{float}
	\usepackage{pdfpages}
	\usepackage{todonotes}
	\usepackage{pst-plot}
	\usepackage{pstricks}
	\usepackage{pstricks-add}
	\usepackage{pst-node}
	\usepackage{pst-grad,multido} 
	\usepackage{verbatim}
	\usepackage{fixltx2e}
	\title{}
	\date{}
	\author{}
	\usepackage{array}
	\usepackage{amsmath}
	\usepackage{fancyhdr}
	\usepackage{enumitem} 
	\parindent0pt
	%\usepackage[format=plain, justification=RaggedRight, singlelinecheck=false]{caption}
	\usepackage{blindtext}
	
	% Listings
	\usepackage{listings}
	\renewcommand{\lstlistlistingname}{Liste der Quellcode Ausschnitte}
	\renewcommand{\lstlistingname}{Quellcode Ausschnitt}
		\definecolor{lsgreen}{rgb}{0,.5,0}
		\definecolor{lsred}{rgb}{.7,0,0}
		\definecolor{lsorange}{rgb}{.9,.5,0}
		\definecolor{lsgray}{rgb}{.5,.5,.5}
		\lstset{
			frame=tb,
			aboveskip=10mm,
			belowskip=10mm,
			showstringspaces=false,
			columns=flexible,
			captionpos=b,
			basicstyle={\normalsize\ttfamily},
			numbers=left,
			numberstyle=\tiny\color{lsgray},
			keywordstyle=\color{blue},
			commentstyle=\color{lsorange},
			stringstyle=\color{lsgreen},
			breaklines=true,
			breakatwhitespace=true,
			rulecolor=\color{lsgray},
			xleftmargin=7mm,
			tabsize=3
		}
	
	% Needed for proper display of links in bibliography
	\usepackage{url}	
	
	% Hyperref
	\usepackage[
	pdfauthor={Laura Anger, Timo \dots, Lukas Kolhagen},
	pdftitle={BVA Bewegungsanalyse},
	pdftoolbar=true,	
	colorlinks=true,
	linkcolor=blue,
	citecolor=blue,
	urlcolor=blue,
	linktocpage=true
	]{hyperref}
	\usepackage{bookmark}
	\bookmarksetup{
	numbered
	}
	\urlstyle{same}
	
	\pagestyle{fancy}
	\fancyhf{}
	\fancyhead[LO]{BVA}
	\fancyhead[CO]{Bewegungsanalyse in einer Videosequenz}
	\fancyhead[RO]{\thepage}
	\renewcommand{\headrulewidth}{0.5pt}
	\newcommand{\Absatzbox}[1]{\parbox[0pt][2em][c]{0cm}{}}
	
	% Itemize symbol
	\renewcommand{\labelitemi}{$\triangleright$}
	
	% Colors
	\definecolor{yellow}{rgb}{.95,.85,0}
	\definecolor{green}{rgb}{0,.8,0}
	\definecolor{blue}{rgb}{0,0,.8}
	\definecolor{red}{rgb}{.8,0,0}
	\definecolor{grey}{rgb}{.4,.4,.4}
	\definecolor{orange}{rgb}{.9,.5,0}
	
	% Macro for typesetting C++
	\newcommand{\CC}{C\nolinebreak\hspace{-.05em}\raisebox{.4ex}{\tiny\bf +}\nolinebreak\hspace{-.10em}\raisebox{.4ex}{\tiny\bf +}}
\def\CC{{C\nolinebreak[4]\hspace{-.05em}\raisebox{.4ex}{\tiny\bf ++}}}

\begin{document}
\thispagestyle{empty}
	%\sffamily
			\begin{center}
			\includegraphics[width=.35\textwidth]{logo_TH}\\[20ex]
			{\Huge\textbf{Projektdokumentation}}\\[8ex]
			\rule{.8\textwidth}{.2pt}
			{\Large Bewegungsanalyse einer Videosequenz\\[1ex] mit dem Ansatz des Papers
			von Aach und Kunz}\\
			\rule{.8\textwidth}{.2pt}\\[10ex]
			von\\[2ex]
			\begin{tabular}{ll}
			Laura Anger &(Matrikelnr. 11086356)\\ 
			Timo Breuer &(Matrikelnr. XXXXXXXX)\\ 
			Lukas Kolhagen &(Matrikelnr. 11084355)\\
			\end{tabular}\\[10ex]
			Durchgeführt im\\ \textbf{Master Medientechnologie}\\ im\\ 
			\textbf{Sommersemester 2016}\\			
			\end{center}
			\vfill
			\begin{flushleft}
			{\bf Betreuer:}\\
			Prof. Dr. Dietmar Kunz\\
			Institut für Medien- und Phototechnik
			\end{flushleft}
	\newpage
	\tableofcontents
	\newpage
	\section{Einleitung}\todo[inline]{Lukas}
	Diese Ausarbeitung ist Teil der Abschlussprojekt-Dokumentation im Modul "`Weiterführende Themen der Bildverarbeitung"' im Master Medientechnologie an der Technischen Hochschule Köln.
	
	Das Projekt beschäftigte sich mit der Bewegungsanalyse einer Videosequenz mit dem Ansatz des Papers von Aach und Kunz\textsuperscript{\cite{aach1998bayesian}}. Es wurde bearbeitet von Laura Anger, Timo Breuer und Lukas Kolhagen.
	\subsection{Ansatz im Paper von Aach und Kunz}
	Die Grundlage für das vorliegende Projekt bildet das Paper "`Bayesian motion estimation for temporally recursive noise reduction in X-ray fluoroscopy"'. Dieses beschäftigt sich mit der Entwicklung einer robusten Methode zur Bewegungsschätzung für die speziellen Anforderungen der stark rauschenden Aufnahmen einer Röntgen-Fluoroskopie.\\
	Der Ansatz beruht auf der Modellierung drei essenzieller Faktoren:
	\begin{description}
		\item [Datenterm:] Unterschied der Grauwerte zweier aufeinander folgender Bildern.
		\item [Örtliche Kohärenz:] Außer an Randbereichen von Objekten, bewegen sich Nachbarschaften meist in die gleiche Richtung.
		\item [Zeitliche Kohärenz:] Bewegungen verlaufen normalerweise kontinuierlich, sodass sich ein Bildblock zwischen zwei Bildern wahrscheinlich in dieselbe Richtung weiterbewegt oder die Richtung nur gering ändert.
	\end{description}
	Eine genaue Beschreibung dieser Faktoren erfolgt in \ref{sec:costFunc}.\\
	
	\subsection{Projektziel}
	Die Zielsetzung für das Projekt "`Bewegungsanalyse einer Videosequenz"' war eine Über\-tra\-gung des Ansatzes von Röntgenbildern auf normale Videosequenzen. Infolge dessen war eine Vernachlässigung der speziellen Anforderung des Bildrauschens möglich, da Röntgenbilder -- insbesondere als Teil einer Fluoroskopie -- zum Schutz des Patienten und des medizinischen Personals nur sehr geringe Röntgendosen enthalten dürfen und deshalb ein extrem schlechtes Signal-zu-Rauschverhältnis aufweisen. Diese Problematik besteht bei normalen Videosequenzen nicht, weshalb für die Untersuchung von vergleichsweise geringem und etwa gleich verteiltem Rauschen ausgegangen werden konnte.
	
\section{Verfahren}\todo[inline]{Laura}
	In {\cite{aach1998bayesian}} wird das Verfahren, was dieser Ausarbeitung zu Grunde liegt beschrieben. Der dort 				aufgeführte Algorithmus wurde speziell für Röntgenaufnahmen entwickelt, um Arzt und 					Patienten im Rahmen von Behandlungen, welche Röntgenstrahlung verwenden vor gesundheitlichen 			Konsequenzen zu schützen. Es handelt sich bei dem Ansatz um ein Block-Matching Verfahren, 			welche 	dem Satz von Bayes folgen.
	\\Im vorliegenden Fall soll das Verfahren allerdings auf gewöhnlichen Bildsequenzen angewandt 		werden. Im Folgenden wird das zu grundeliegende Verfahren erläutert und auf eventuelle 				Änderungen im Algorithmus eingegangen. 
	
\subsection{Bewegungsschätzung}\todo[inline]{Laura}
Um zu verstehen, wie die Bewegungsschätzung im einzelnen funktioniert, muss man sich zunächst 
klar machen, wie das geschätzte Bewegungsvektorfeld überhaupt definiert ist.\\

\begin{figure}[H]
		\centering
		\includegraphics[bb=0 0 256 256, scale=0.5]{beziehung-bild-bewegungsfeld.png}
		\caption{Beziehung zwischen Bewegungsvektorfeld und Einzelbildern [1]}
		\label{fig:beziehung}
	\end{figure}

In Abbildung \ref{fig:beziehung} sieht man drei Frames einer Bildsequenz. $Y_{n}$ steht hierbei für das $n$-te Bild dieser Sequenz und $y_{n}(k)$ ist der Grauwert des Pixels an der Stelle $k$. Das $k$ steht für ein Koordinatenpärchen ($k_{x},k_{y}$) und es gilt $k=1,\dots,N$, wobei $N$ die Anzahl der Pixel eines Frames ist. Der eingezeichnete Vektor $v_{n}(k)$ ist derjenige Vektor, der auf $k$ addiert wird, sodass sich die Position des entsprechenden Pixels im vorherigen Bild ergibt. All diese Bewegungsvektoren zusammengenommen ergeben das Bewegungsvektorfeld eines Frames, welches in der Abbildung mit $V_{n}$ bezeichnet wird. \\
Das geschätzte Bewegungsvektorfeld $\hat{V}_{n}$ ergibt sich nach den Ausführungen von Aach und Kunz zu: 
	
\begin{equation}
	\hat{V}_{n}=\arg\ \smash{\displaystyle\max_{V}} \left[p(Y_{n},  Y_{n-1},\vert V)\cdot p(\hat{V}_{n-1} \vert V)\cdot p(V)\right]
	\label{eq:bayes}
\end{equation}\\
	
Da es sich um einen bayesschen Ansatz handelt, gilt es sich mit bedingten Wahrscheinlichkeiten auseinander zu setzen. Der erste Faktor der Formel \ref{eq:bayes} ist im Originalansatz zur Modellierung des Rauschens gedacht. Es ist davon auszugehen, dass Röntgenbilder weit aus mehr verrauscht sind, als reale Bildsequenzen auf die das vorliegende Verfahren angewandt werden soll. Deshalb liegt es nahe, dass Rauschen weitgehend zu vernachlässigen und durch einen reinen Datenterm zu ersetzen. Mehr Details dazu kann man in Kapitel \ref{ch:Datenterm} nachlesen. Bei den beiden anderen Faktoren handelt es sich zum einen um die örtliche und zum anderen um die zeitliche Kohärenz. Beide werden in den Kapiteln \ref{ch:oertlich} bzw. \ref{ch:zeitlich} näher beschrieben.
		
		\subsection{Programmablauf}
		Der Programmablauf des ImageJ-Plug-Ins in Form der \texttt{run()}-Methode, die aufgrund des implementierten \texttt{PlugInFilter}-Interfaces überschrieben werden muss, ist in Abbildung~\ref{fig:programmAblauf} dargestellt.\\
		Grob betrachtet, werden in der \texttt{run()}-Methode drei \texttt{for}-Schleifen geschachtelt ausgeführt. Die innerste Schleife läuft über jeden Block des Bildes und bestimmt für diesen den Bewegungsvektor mit den geringsten Kosten aus den 14 berechneten Alternativen. Die Blockgröße ist variabel und kann z.\,B. $8\times8$ betragen.\\
		Die nächst äußere Schleife ist für die Iterationen zuständig. In den Iterationen wird innerhalb eines Bildes des Input-Stacks das Bewegungsvektorfeld mehrfach berechnet und jeweils das zuletzt berechnete Ergebnis als Grundlage für die nächste Berechnung verwendet. Dies ist erforderlich, um die Abweichung der Bewegungsvektoren pro Frame so gering wie möglich zu halten. Gleichzeitig hängt die Wahl der Anzahl der Iterationen natürlich davon ab, welche Performanz die Berechnung erreichen soll, also wie schnell ein Ergebnis benötigt wird.\\
		Die äußere Schleife läuft über den Stack und sorgt somit dafür, dass die Berechnungen pro Block und Iteration jeweils für jedes Bild des Input-Stacks erfolgen.\\
		Sobald ein Bild fertig bearbeitet ist, die äußere Schleife also einen Durchlauf absolviert hat, wird der Fortschrittsbalken im ImageJ-Fenster aktualisiert, damit der Benutzer eine Rückmeldung bekommt, wie weit die Berechnung fortgeschritten ist.\\
		Zuletzt wird in der \texttt{run()}-Methode noch das Ausgabefenster, in welchem der Input-Stack inklusive der überlagerten Bewegungsvektorfelder dargestellt wird, generiert und dessen Methode zur Anzeige aufgerufen.
		\begin{comment}
			\begin{figure}[h!]
			\centering
					\begin{psmatrix}[rowsep=0.3,colsep=0.4]
						\rnode{run}{\psframebox[fillstyle=solid,fillcolor=black]{\footnotesize\color{white}public void run(ImageProcessor ip)}}\\
						\rnode{readStack}{\psframebox[linearc=0.05,cornersize=absolute,fillstyle=solid,fillcolor=black!10]{\footnotesize Read data from stack}}\\
						\rnode{initialize}{\psframebox[linearc=0.05,cornersize=absolute,fillstyle=solid,fillcolor=black!10]{\footnotesize Initialize first motion vector field with zero vectors}}\\
						\rnode{forI}{\psframebox[linearc=0.05,cornersize=absolute,fillstyle=solid,fillcolor=black!10]{\footnotesize\texttt{$i=0$}}}\\
						\dianode[fillstyle=solid,fillcolor=red!30]{condStackSize}{\footnotesize$i<$ \texttt{stack size}?}\\[3mm]
						\dianode[fillstyle=solid,fillcolor=red!30]{frameNotZero}{\footnotesize$i\not=$ \texttt{0}?}\\[3mm]
						\rnode{curFrame}{\psframebox[linearc=0.05,cornersize=absolute,fillstyle=solid,fillcolor=black!10]{\footnotesize Set current frame to i}}\\
						\rnode{forJ}{\psframebox[linearc=0.05,cornersize=absolute,fillstyle=solid,fillcolor=black!10]{\footnotesize\texttt{$j=0$}}}\\
						\dianode[fillstyle=solid,fillcolor=red!30]{condIter}{\footnotesize$j<$ \texttt{iterations}?}\\[3mm]
						\rnode{Vn}{\psframebox[linearc=0.05,cornersize=absolute,fillstyle=solid,fillcolor=black!10]{\footnotesize Set current vector field as previous}}\\
						\rnode{forK}{\psframebox[linearc=0.05,cornersize=absolute,fillstyle=solid,fillcolor=black!10]{\footnotesize\texttt{$k=0$}}}\\
						\dianode[fillstyle=solid,fillcolor=red!30]{condNumBlocks}{\footnotesize$k<$ \texttt{number of blocks}?}\\[3mm]
						\rnode{calcAlt}{\psframebox[linearc=0.05,cornersize=absolute,fillstyle=solid,fillcolor=black!10]{\footnotesize Calculate 14 alternatives for block k}}\\
						\rnode{minimizeCost}{\psframebox[linearc=0.05,cornersize=absolute,fillstyle=solid,fillcolor=black!10]{\footnotesize Minimize cost function for alternatives}}\\
						\rnode{addVec}{\psframebox[linearc=0.05,cornersize=absolute,fillstyle=solid,fillcolor=black!10]{\footnotesize Add vector with minimal cost to motion vector field}}\\
						\rnode{updateProgress}{\psframebox[linearc=0.05,cornersize=absolute,fillstyle=solid,fillcolor=black!10]{\footnotesize Update plug-in progress}}\\
						\rnode{genMVF}{\psframebox[linearc=0.05,cornersize=absolute,fillstyle=solid,fillcolor=black!10]{\footnotesize Generate motion vector field visualization for current frame}}\\
						\rnode{addToOutStack}{\psframebox[linearc=0.05,cornersize=absolute,fillstyle=solid,fillcolor=black!10]{\footnotesize Add motion vector field to output stack}}\\
						\rnode{outWindow}{\psframebox[linearc=0.05,cornersize=absolute,fillstyle=solid,fillcolor=black!10]{\footnotesize Generate and display output window}}\\
					\end{psmatrix}
					\psset{arrows=->,nodesep=0pt}
					\ncline{run}{readStack}
					\ncline{readStack}{initialize}
					\ncline{initialize}{forI}
					\ncline{forI}{condStackSize}
					\ncline{condStackSize}{frameNotZero}\nbput{\footnotesize\color{green}True}
					\ncangle[angle=0, linearc=.1]{frameNotZero}{genMVF}\nbput[npos=.15]{\footnotesize\color{red}False}
					\ncline{frameNotZero}{curFrame}\nbput{\footnotesize\color{green}True}
					\ncline{curFrame}{forJ}
					\ncline{forJ}{condIter}					
					\ncline{condIter}{Vn}\nbput{\footnotesize\color{green}True}
					\ncline{Vn}{forK}
					\ncline{forK}{condNumBlocks}
					\ncline{condNumBlocks}{calcAlt}\nbput{\footnotesize\color{green}True}
					\ncline{calcAlt}{minimizeCost}
					\ncline{minimizeCost}{addVec}
					\ncline{addVec}{updateProgress}
					\ncangle[arm=3cm, angle=180, linearc=.1]{condIter}{updateProgress}\nbput[npos=.25]{\footnotesize\color{red}False}
					\ncangle[arm=1.8cm, angle=0, linearc=.1]{condNumBlocks}{condIter}\nbput[npos=.25]{\footnotesize\color{red}False}
					\ncline{updateProgress}{genMVF}
					\ncline{genMVF}{addToOutStack}
					\ncline{addToOutStack}{outWindow}
					\ncangle[arm=2.8cm, angle=180, linearc=.1]{condStackSize}{outWindow}\nbput[npos=.2]{\footnotesize\color{red}False}
			\caption{Programmablauf}
			\label{fig:programmAblauf}
		\end{figure}
\end{comment}		
		
		\subsection{Kostenfunktion}\label{sec:costFunc}\todo[inline]{Alle}
			\subsubsection{Datenterm}\todo[inline]{Lukas}\label{ch:Datenterm}
			\subsubsection{Örtliche Kohärenz}\todo[inline]{Timo}\label{ch:oertlich}
			\subsubsection{Zeitliche Kohärenz}\todo[inline]{Lukas}\label{ch:zeitlich}
\subsection{Visualisierung}\todo[inline]{Laura}
	Um die Bewegungsvektorfelder darzustellen, wird sich mit Symbolen beholfen. Diese werden 				blockweise  über die Videosequenz gelegt. Aus Darstellungsgründen wird das Video dazu um Faktor 	4 in beide Bildrichtungen hoch skaliert. Da die einzelnen Bewegungsvektoren immer zwischen zwei 		Frames berechnet werden, wird genau ein Bewegungsvektorfeld weniger erzeugt, als das 					Eingangsmaterial Frames hat. \\
	Bei den bereits erwähnten Symbolen handelt es sich um Kreise und Pfeile. Ein Kreis wird immer 		dann genutzt, wenn für den entsprechenden Block keine oder nur eine kleine Bewegung durch das 		Verfahren ermittelt wurde. Die Pfeile zeigen immer in Richtung der ermittelten Verschiebung. 			Beide Symbole haben ihren Startpunkt im Mittelpunkt des jeweiligen Blocks.\\
	Die Randbereiche der einzelnen Bewegungsvektorfelder werden bei der Visualisierung ausgespart, 
	da hier durch den Algorithmus begründete Fehlberechnungen auftreten.
	\section{Auswertung}\todo[inline]{Laura \& Timo}

\subsection{Testmaterial}\todo[inline]{Laura}
	Das Verfahren wird anhand von drei unterschiedlichen Bildsequenzen getestet, die im Folgenden 		Testmaterial 1-3 genannt werden und alle eine Auflösung von 256x2656 Pixeln haben. Bei 				Testmaterial 1 und Testmaterial 2 wurde ein Bild um bekannte Werte in x- und y-Richtung 				verschoben. Anzumerken ist auch, dass beide Testmaterialien identisch verschoben wurden. Bei 			Testmaterial 3 kann die Bewegung der zu sehenden Objekte lediglich geschätzt werden. Alle 			Testmaterialien wurden für diese Dokumentation aufgenommen bzw. erstellt.\vspace{0.6cm}

\begin{minipage}{0.5\textwidth}
	\begin{figure}[H] 
		\includegraphics[bb=0 0 256 256, scale=0.77]{Testmaterial1.jpg}
			\label{fig:testmaterial1}
			\caption{Standbild Testmaterial 1.}
	\end{figure}
\end{minipage}
\begin{minipage}{0.5\textwidth}
	\textbf{Testmaterial 1}\\
	Diese Bildsequenz besteht aus 150 Frames und wurde aus einem Bild der Stadt Köln erzeugt.\\ 
	Bei den ersten und letzten 50 Frames wird ein Ausschnitt des Bildes um jeweils 10 Pixel 				nach links bzw. oben verschoben. In den mittleren 50 Frames  wird der Bildinhalt um 10 				Pixel nach links und 10 Pixel nach unten verschoben. 
	\vspace{2.0cm}\\
\end{minipage}\vspace{0.7cm}

\begin{minipage}{0.5\textwidth}
	\begin{figure}[H] 
		\includegraphics[bb=0 0 256 256, scale=0.77]{Testmaterial2.jpg}
			\label{fig:testmaterial2}
			\caption{Standbild Testmaterial 2.}
	\end{figure}
\end{minipage}
\begin{minipage}{0.5\textwidth}
	\textbf{Testmaterial 2}\\
	Auf den 150 Frames, die diese Bildsequenz umfasst ist ein Blumenmotiv zu sehen, welches jeweils 	über 50 Frames in verschiedene Richtungen verschoben wird. Auf den ersten Frames erfolgt eine 		Verschiebung um 10 Pixel nach links. Während die mittleren Frames um sowohl 10 Pixel nach 			links, als auch 10 Pixel nach oben verschoben wurden, wurde der Bildinhalt der verbleibenden 			Frames nur um 10 Pixel nach oben verschoben.
	\vspace{0.9cm}\\
\end{minipage}\vspace{0.7cm}


\begin{minipage}{0.5\textwidth}
	\begin{figure}[H] 
		\includegraphics[bb=0 0 256 256, scale=0.77]{Testmaterial3.jpg}
			\label{fig:testmaterial3}
			\caption{Standbild Testmaterial 3.}
	\end{figure}
\end{minipage}
\begin{minipage}{0.5\textwidth}
	\textbf{Testmaterial 3}\\
	Bei Testmaterial 3 handelt es sich um eine reale Videosequenz, die in Köln Ehrenfeld 					aufgenommen wurde. Zu sehen sind ein Auto, dass sich von links nach rechts durch das Bild 			bewegt und eine Fahrradfahrerin, die das Bild genau entgegengesetzt durchfährt. Beide Objekte 		werden zeitweise durch verschiedene Objekte verdeckt. Die Kamera ist starr, weshalb für den 			restlichen Bildinhalt keine Bewegung zu erkennen ist. Insgesamt besteht die Testsequenz aus 118 	Frames.
	\vspace{0.4cm}\\
\end{minipage}

\subsection{Auswertung Testmaterial 1 und Testmaterial 2}\todo[inline]{Laura}
\subsection{Auswertung Testmaterial 3}\todo[inline]{Laura}
Die Bewegung im vorliegenden Testmaterial kann lediglich optisch ausgewertet werden, da die tatsächlichen Bewegungsvektoren nicht bekannt sind. Für die Bewegungsdetektion wurden die folgenden Einstellungen getroffen. \\\\
\textbf{Parameter:} 
\begin{itemize} 
\item 5 Iterationen
\item $\nu$ = 1.5
\item $\lambda$ = 0.3 und $\lambda$\textsubscript{T} = 0.3
\end{itemize}

Abbildung \ref{fig:frame43} und Abbildung \ref{fig:frame47} zeigen jeweils ein Standbild aus dem Bewegungsvektorfeld, welches sich unter dem Namen \textit{testmaterial3-bewegungsvektorfeld.tiff} auf der beiliegenden Daten-CD befindet.\\
Es ist deutlich zu erkennen, dass die Bereiche in denen keine Bewegung stattfindet weitgehend richtig detektiert wurden. Und auch die Bewegung des Autos und der Radfahrerin werden trotz der Verdeckung durch die Säule weitgehend erkannt. Auffällig ist, dass besonders die Blöcke, die hinter dem Auto liegen und deren Bildinhalt sich nicht mehr bewegt falsch berechnet sind. Das ist besonders gut in Abbildung \ref{fig:frame47} zu sehen und lässt sich auf das Einschwingverhalten zurückführen. Dieses wird in Kapitel \ref{ch:Einschwingverhalten} erklärt und ausgewertet.

\begin{minipage}{0.5\textwidth}
	\begin{figure}[H] 
		\includegraphics[scale=0.42]{frame43.png}
		\caption{Bewegungsvektorfeld Testmaterial 3. Frame 43.}
		\label{fig:frame43}
	\end{figure}
\end{minipage}
\begin{minipage}{0.5\textwidth}
	\begin{figure}[H] 
		\includegraphics[scale=0.42]{frame47.png}
		\caption{Bewegungsvektorfeld Testmaterial 3. Frame 47.}
		\label{fig:frame47}
	\end{figure}
\end{minipage}

\subsection{Einschwingverhalten} \label{ch:Einschwingverhalten}
Als Ausgangspunkt werden alle Bewegungsvektorfelder zu Beginn des Algorithmus auf den Nullvektor gesetzt. Das Verfahren muss sich also zunächst Einschwingen. Dabei wird im Folgenden zwischen dem interframe und dem intraframe Einschwingen unterschieden.	

\subsubsection{Bewegungsvektorfelder}\todo[inline]{Timo}

\subsubsection{Innerhalb eines Bildes}\todo[inline]{Laura}

		\subsection{Parameter der Regularisierungsterme}\todo[inline]{Timo}
	\section{Zusammenfassung}\todo[inline]{Lukas}
	\section{Arbeitsaufteilung der Dokumentation}
	\newpage
	\bibliographystyle{plain}
	\bibliography{ABV_Bewegungsanalyse_LaTeX}
\end{document}
		